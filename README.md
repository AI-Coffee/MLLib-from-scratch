<h1 align="center"> Machine Learning Library from Scratch with Python</h1>

## üëã Introduction

In this project, I will "re-built from scratch" state-of-the-art algorithms in ML/DL, but using only Python language. I will use **NumPy library** for better performance on matrix calculation.

One thing you need to know that, I make this project **just for learning and understanding algorithms deeply**, not suitable to apply in real-world problems. I still recommend using many other SOTA libraries for building models.


## üë§ Contributors
**I would like to express my sincere thanks to the these wonderful people who have contributed to this library with me:**

<table>
  <tbody>
    <tr>
      <td align="center"><a href="http://duongttr.github.io"><img src="https://avatars.githubusercontent.com/u/34759421?v=4?s=100" width="100px;" alt="Duong Tran Thanh"/><br /><sub><b>Duong Tran Thanh</b></sub></a><br /><a href="#mentoring-duongttr" title="Mentoring">üßë‚Äçüè´</a></td>
      <td align="center"><a href="https://github.com/tanthinhdt"><img src="https://avatars.githubusercontent.com/u/76445277?v=4?s=100" width="100px;" alt="Thinh Duong Tan"/><br /><sub><b>Thinh Duong Tan</b></sub></a><br /><a href="https://github.com/AI-Coffee/mllib-from-scratch/commits?author=tanthinhdt" title="Code">üíª</a></td>
      <td align="center"><a href="https://github.com/pphuc25"><img src="https://avatars.githubusercontent.com/u/81808312?v=4?s=100" width="100px;" alt="Phuc Phan Van"/><br /><sub><b>Phuc Phan Van</b></sub></a><br /><a href="https://github.com/AI-Coffee/mllib-from-scratch/commits?author=pphuc25" title="Code">üíª</a></td>
    </tr>
  </tbody>
</table>


## üìù Libraries

### A. Classification
1. [**Logistic Regression**](classification/LogisticRegression.py)
2. Naive Bayes
3. [**K-Nearest Neighbors (KNN)**](classification/KNN.py)
4. Decision Tree
5. Support Vector Machine (SVM)
6. Random Forest
7. Softmax Regression

### B. Regression
1. [**Linear Regression**](regression/LinearRegression.py)
2. Ridge Regression
3. Lasso Regression
4. Decision Tree for Regression
5. Random Forest for Regression
6. K-Nearest Neighbors for Regression
7. Support Vector Regression
8. Gaussian Regression
9. Polynomial Regression

### C. Clustering
1. [**K-Means**](cluster/KMeans.py)
2. DBSCAN
3. Mean Shift
4. OPTICS
5. Spectral Clustering
6. Mixture of Gaussians
7. Affinity Propagation
8. Agglomerative Clustering
9. BIRCH

### D. Dimensionality reduction
1. [**Principal Components Analysis (PCA)**](decomposition/PCA.py)
2. Factor Analysis (FA)
3. Linear Discriminant Analysis (LDA)
4. Truncated SVD
5. Kernel PCA
6. t-Distributed Stochastic Neighbor Embedding (t-SNE)
7. Multidimensional Scaling (MDS)
8. Isomap

## Contributors ‚ú®

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->
<!-- ALL-CONTRIBUTORS-LIST:END -->

This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!